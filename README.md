This project is a **legal question answering backend** using **FastAPI** and a **free, local AI model**. It reads your `.pdf` or `.docx` legal documents, finds relevant parts, and generates an answer.

---

## ğŸ“ Folder Structure

```
lexi.sg-rag-backend-test/
â”œâ”€â”€ app/                     # All the Python code
â”‚   â”œâ”€â”€ main.py              # FastAPI API routes
â”‚   â”œâ”€â”€ document_loader.py   # Loads and reads DOCX and PDF
â”‚   â”œâ”€â”€ embedder.py          # Embeds document chunks with FAISS
â”‚   â”œâ”€â”€ rag_pipeline.py      # Runs the query-retrieve-generate logic
â”‚   â””â”€â”€ llm.py               # The AI model (e.g., flan-t5-large)
â”‚
â”œâ”€â”€ data/legal_docs/         # ğŸ“¥ Add your legal documents here
â”œâ”€â”€ requirements.txt         # All required Python libraries
â”œâ”€â”€ README.md                # This guide
```

### Create Virtual Environment

python -m venv venv
venv\Scripts\activate   # On Windows



###  Start the Server
```bash
uvicorn app.main:app --reload
```
Visit:
ğŸ‘‰ http://127.0.0.1:8000/docs

---

## ğŸ“¬ Using the `/query` Endpoint

### Method: `POST`
### URL: `http://127.0.0.1:8000/query`

Create data/legal_docs/ to add all the documents

Requirements

fastapi
uvicorn
sentence-transformers
faiss-cpu
python-docx
PyMuPDF
transformers
torch

